---
{"dg-publish":true,"permalink":"/data-career/ho-creato-una-ia-privata-per-ortix/","title":"ğŸ¤– Progetto AI Vault Ortix - Resoconto","tags":["AI","LLM","Obsidian","llama_index","localAI","embedding","ETL","SovranitÃ  Digitale"]}
---

---
dg-publish: true
dg-home: false
title: "ğŸ§  Ho creato una IA privata per Ortix"
date: 2025-08-01
tags: [AI, Ortix, SovranitÃ  Digitale, Obsidian, Local AI, LLM, Privacy]
---

# ğŸ§  Ho creato una IA privata per Ortix

![Pasted image 20250801183101.png](/img/user/Pasted%20image%2020250801183101.png)

ğŸŒ± **Ortix** Ã¨ il mio giardino digitale, uno spazio dove conservo tutta la mia conoscenza, idee e riflessioni.  
Da tempo sognavo di poterci *parlare* direttamente, come se fosse una mente secondaria sempre disponibile, **senza passare da ChatGPT, Gemini o altri servizi esterni**.  
In una parola: **una IA tutta mia**, in locale, senza internet, nel pieno rispetto della mia **[[Ortix/Filosofia/ğŸ›¡ï¸ SovranitÃ  digitale\|ğŸ›¡ï¸ SovranitÃ  digitale]]**.

---

## âš™ï¸ Cosa ho fatto

ğŸ’¾ Ho usato **#Python** per scrivere un piccolo programma che:
- Legge tutti i miei file Markdown di Ortix
- Li trasforma in un formato comprensibile per una IA (embedding)
- Li collega a un **modello LLM locale**, che puÃ² rispondere in linguaggio naturale

ğŸ§  Allâ€™inizio ho scaricato due modelli:  
- uno per *capire* il contenuto (`all-MiniLM`, molto leggero, ottimo per trasformare i testi in vettori),  
- uno per *rispondere* alle domande (`llama-3-8b-instruct`, un grande modello linguistico locale, da usare al posto di ChatGPT).

![Pasted image 20250801182941.png](/img/user/Pasted%20image%2020250801182941.png)

ğŸ‘ğŸ» Al primo tentativo, **ha funzionato**... ma:
- ci ha messo **6 minuti per rispondere**,
- **solo in inglese**!

---

## ğŸ›  Come lâ€™ho migliorata

ğŸ”§ Ho allora:
- Scaricato un **modello piÃ¹ leggero**, adatto al mio PC di 5 anni fa
- Aggiunto un **system prompt** per dirgli di rispondere sempre in italiano e in modo chiaro

![Pasted image 20250801182954.png](/img/user/Pasted%20image%2020250801182954.png)

âœ… CosÃ¬ facendo, ho ottenuto un assistente in grado di leggere Ortix e rispondere alle mie domande.  
Certo, una risposta puÃ² richiedere anche **3 minuti**, ma funziona! E **tutto in locale**.

---

## ğŸ§ª Quale modello scegliere?

ğŸ“Š Ecco una tabella con le principali opzioni che ho testato, con RAM minima, velocitÃ  e qualitÃ :

| Modello GGUF          | RAM Minima  | VelocitÃ  CPU | QualitÃ        |
|------------------------|-------------|--------------|----------------|
| `llama-3-8b Q4_K_M`    | 20+ GB      | ğŸ¢ Lento     | ğŸ”¥ Alta        |
| `mistral-7b Q4_K_M`    | 12 GB       | ğŸŒ Media     | ğŸ”¥ Alta        |
| `phi-2 Q4_K_M`         | 6â€“8 GB      | âš¡ï¸ Veloce    | ğŸ‘ Buona       |
| `llama-3-8b Q2_K`      | 10â€“12 GB    | âš ï¸ PiÃ¹ veloce | ğŸ˜ QualitÃ  bassa |

ğŸ’¡ La scelta dipende dal tuo hardware e dai tuoi obiettivi: qualitÃ , velocitÃ  o leggerezza.

---

## ğŸ“ Cosa ho imparato

- Non serve un super computer per costruire una IA personale
- Esistono modelli gratuiti e [[Bitcoin/ğŸ§¬ Open Source\|ğŸ§¬ Open Source]] che puoi usare liberamente
- Ãˆ **possibile creare un assistente privato** partendo solo da qualche nozione di Python
- Una volta impostato il sistema, posso **cambiare modelli, migliorare le risposte**, oppure usare plugin Obsidian per automatizzare tutto

---

ğŸ“ Ãˆ stato un esperimento istruttivo e stimolante.  
Ora posso chiedere a Ortix *â€œCos'Ã¨ un Full Node?â€* e lui mi rispondeâ€¦  
con calma ğŸ˜…, ma **senza spiare nulla a nessuno**.

---

[[Data Career/ğŸ§  Da Data Manager a giardiniere digitale\|ğŸ§  Da Data Manager a giardiniere digitale]]

#Ortix #AI #LLM #LocalAI #Obsidian #Python #SovranitÃ Digitale
